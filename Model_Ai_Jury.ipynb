{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C5rWc76Id_5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9430f32c-5fef-45fd-cdae-400f33db674a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.10.6)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.47)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, groovy, ffmpy, faiss-cpu, aiofiles, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aiofiles-23.2.1 faiss-cpu-1.10.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.47)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.39)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (0.3.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.21->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.20 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain transformers faiss-cpu sentence-transformers fastapi pydantic uvicorn gradio\n",
        "!pip install langchain-community\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from typing import Dict, List, Any\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "import gradio as gr\n",
        "\n",
        "# LangChain\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "# Configure\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample  case data\n",
        "SAMPLE_CASES = [\n",
        "    {\n",
        "        \"title\": \"Privacy as a Fundamental Right\",\n",
        "        \"citation\": \"Justice K.S. Puttaswamy v. Union of India (2017)\",\n",
        "        \"court\": \"Supreme Court of India\",\n",
        "        \"content\": \"The Supreme Court recognized the right to privacy as a fundamental right under Article 21 of the Constitution. The Court held that the right to privacy is intrinsic to life and liberty and is inherently protected under the various fundamental freedoms enshrined under Part III of the Indian Constitution.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Online Defamation\",\n",
        "        \"citation\": \"Swami Ramdev v. Facebook (2019)\",\n",
        "        \"court\": \"Delhi High Court\",\n",
        "        \"content\": \"The Delhi High Court ruled that social media platforms must remove defamatory content globally if it originates from India. The court held that defamation on social media has wide-reaching consequences and platforms cannot claim jurisdiction limitations.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Environmental Protection\",\n",
        "        \"citation\": \"M.C. Mehta v. Union of India (Taj Trapezium Case)\",\n",
        "        \"court\": \"Supreme Court of India\",\n",
        "        \"content\": \"The Supreme Court ordered industries around the Taj Mahal to either switch to natural gas or relocate outside the Taj Trapezium Zone to protect the monument from pollution damage, invoking the 'Polluter Pays Principle' and Article 21 of the Constitution.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Free Speech Online\",\n",
        "        \"citation\": \"Shreya Singhal v. Union of India (2015)\",\n",
        "        \"court\": \"Supreme Court of India\",\n",
        "        \"content\": \"The Supreme Court struck down Section 66A of the Information Technology Act, holding it violative of Article 19(1)(a) of the Constitution. The Court differentiated between advocacy and incitement, holding that only the latter can be prohibited.\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Digital Privacy\",\n",
        "        \"citation\": \"Internet Freedom Foundation v. Union of India (2022)\",\n",
        "        \"court\": \"Delhi High Court\",\n",
        "        \"content\": \"The Delhi High Court ruled that digital surveillance without proper safeguards violates the right to privacy. The court mandated that any surveillance must follow due process, establish necessity, and be proportionate to the objective sought.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Sample statutes\n",
        "SAMPLE_STATUTES = {\n",
        "    \"The Constitution of India, Article 21\": \"No person shall be deprived of his life or personal liberty except according to procedure established by law.\",\n",
        "    \"The Information Technology Act, Section 66\": \"If any person, dishonestly or fraudulently, does any act referred to in section 43, he shall be punishable with imprisonment for a term which may extend to three years or with fine which may extend to five lakh rupees or with both.\",\n",
        "    \"The Indian Penal Code, Section 499\": \"Whoever, by words either spoken or intended to be read, or by signs or by visible representations, makes or publishes any imputation concerning any person intending to harm, or knowing or having reason to believe that such imputation will harm, the reputation of such person, is said to defame that person.\",\n",
        "    \"The Environment Protection Act, 1986, Section 3\": \"Subject to the provisions of this Act, the Central Government shall have the power to take all such measures as it deems necessary or expedient for the purpose of protecting and improving the quality of the environment and preventing, controlling and abating environmental pollution.\",\n",
        "    \"Right to Information Act, 2005, Section 8\": \"Notwithstanding anything contained in this Act, there shall be no obligation to give any citizen information disclosure of which would prejudicially affect the sovereignty and integrity of India, the security, strategic, scientific or economic interests of the State, relation with foreign State or lead to incitement of an offence.\"\n",
        "}\n",
        "\n",
        "# demo directories\n",
        "os.makedirs(\"case_data\", exist_ok=True)\n",
        "os.makedirs(\"model_cache\", exist_ok=True)\n",
        "os.makedirs(\"vector_db\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Kr5jOiRlld8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM Model\n",
        "\n",
        "def load_language_model():\n",
        "    \"\"\"Load a language model suitable for legal reasoning\"\"\"\n",
        "    logger.info(\"Loading language model...\")\n",
        "\n",
        "    # For Colab, we use a smaller model that can run efficiently\n",
        "    model_name = \"TheBloke/Llama-2-7B-Chat-GGML\"\n",
        "\n",
        "    try:\n",
        "        # Using the HF model directly for simplicity in Colab\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"meta-llama/Llama-2-7b-chat-hf\",\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16,\n",
        "            load_in_8bit=True\n",
        "        )\n",
        "\n",
        "        llm_pipeline = pipeline(\n",
        "            \"text-generation\",\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            max_length=2048,\n",
        "            temperature=0.3,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "        )\n",
        "\n",
        "        llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "        logger.info(\"Language model loaded successfully\")\n",
        "        return llm\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading model: {str(e)}\")\n",
        "        logger.info(\"Using a smaller model for demonstration purposes\")\n",
        "\n",
        "        def simple_llm(prompt):\n",
        "            \"\"\"Simple mock LLM for demonstration when hardware is limited\"\"\"\n",
        "            return f\"Based on the legal analysis of the case presented, I find that...\\n\\n\" + \\\n",
        "                   f\"The key legal issues identified are related to the primary dispute.\\n\\n\" + \\\n",
        "                   f\"After careful consideration of the statutes and precedents, my judgment is that...\\n\\n\" + \\\n",
        "                   f\"This ruling is supported by previous cases including {SAMPLE_CASES[0]['citation']}.\"\n",
        "\n",
        "        return simple_llm\n",
        "\n",
        "def setup_vector_database():\n",
        "    \"\"\"Set up the vector database for legal case retrieval\"\"\"\n",
        "    logger.info(\"Setting up vector database for case law...\")\n",
        "\n",
        "    try:\n",
        "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "        # Converting sample cases to documents\n",
        "        documents = []\n",
        "        for case in SAMPLE_CASES:\n",
        "            documents.append(\n",
        "                Document(\n",
        "                    page_content=f\"{case['title']}: {case['content']}\",\n",
        "                    metadata={\n",
        "                        \"citation\": case[\"citation\"],\n",
        "                        \"court\": case[\"court\"],\n",
        "                        \"title\": case[\"title\"]\n",
        "                    }\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Creating FAISS index\n",
        "        vector_db = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "        # Save database\n",
        "        vector_db.save_local(\"vector_db/legal_cases\")\n",
        "\n",
        "        logger.info(\"Vector database created and saved successfully\")\n",
        "        return vector_db\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error setting up vector database: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Rv-zCj3LloKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AI Judge\n",
        "\n",
        "class AIJudge:\n",
        "    def __init__(self, llm=None, vector_db=None):\n",
        "        \"\"\"Initialize the AI Judge component\"\"\"\n",
        "        logger.info(\"Initializing AI Judge system...\")\n",
        "\n",
        "        # Initialize or load models\n",
        "        self.llm = llm or load_language_model()\n",
        "\n",
        "        # Initialize or load vector database\n",
        "        if vector_db is not None:\n",
        "            self.vector_db = vector_db\n",
        "        elif os.path.exists(\"vector_db/legal_cases\"):\n",
        "            embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "            self.vector_db = FAISS.load_local(\"vector_db/legal_cases\", embeddings)\n",
        "        else:\n",
        "            self.vector_db = setup_vector_database()\n",
        "\n",
        "        # Set up legal reasoning prompt templates\n",
        "        self._setup_prompt_templates()\n",
        "\n",
        "        logger.info(\"AI Judge initialized successfully\")\n",
        "\n",
        "    def _setup_prompt_templates(self):\n",
        "        \"\"\"Set up the prompt templates for legal reasoning\"\"\"\n",
        "        # Case analysis prompt\n",
        "        self.case_analysis_prompt = PromptTemplate(\n",
        "            input_variables=[\"case_facts\", \"petitioner_arguments\", \"respondent_arguments\",\n",
        "                           \"statutes\", \"precedents\"],\n",
        "            template=\"\"\"\n",
        "            You are an AI judge analyzing a legal case in the Indian legal system. Based on the\n",
        "            information provided, generate a comprehensive legal analysis.\n",
        "\n",
        "            CASE FACTS:\n",
        "            {case_facts}\n",
        "\n",
        "            PETITIONER'S ARGUMENTS:\n",
        "            {petitioner_arguments}\n",
        "\n",
        "            RESPONDENT'S ARGUMENTS:\n",
        "            {respondent_arguments}\n",
        "\n",
        "            RELEVANT STATUTES:\n",
        "            {statutes}\n",
        "\n",
        "            RELEVANT PRECEDENTS:\n",
        "            {precedents}\n",
        "\n",
        "            Provide your analysis in the following structure:\n",
        "            1. IDENTIFICATION OF LEGAL ISSUES: What are the key legal questions?\n",
        "            2. ANALYSIS OF FACTS: Analyze relevant facts in light of applicable law.\n",
        "            3. APPLICATION OF STATUTES: Interpret and apply the relevant statutory provisions.\n",
        "            4. PRECEDENT CONSIDERATION: How do the precedent cases apply?\n",
        "            5. LEGAL REASONING: Provide detailed legal reasoning for your conclusion.\n",
        "            6. PRELIMINARY JUDGMENT: State your preliminary judgment.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    def retrieve_relevant_precedents(self, case_text, k=3):\n",
        "        \"\"\"Retrieve relevant legal precedents for a case\"\"\"\n",
        "        if self.vector_db is None:\n",
        "            # Return sample data if vector DB isn't available\n",
        "            return SAMPLE_CASES[:k]\n",
        "\n",
        "        try:\n",
        "            results = self.vector_db.similarity_search(case_text, k=k)\n",
        "            precedents = []\n",
        "\n",
        "            for doc in results:\n",
        "                precedents.append({\n",
        "                    \"content\": doc.page_content,\n",
        "                    \"citation\": doc.metadata.get(\"citation\", \"Unknown\"),\n",
        "                    \"court\": doc.metadata.get(\"court\", \"Unknown\"),\n",
        "                    \"title\": doc.metadata.get(\"title\", \"Unknown\")\n",
        "                })\n",
        "\n",
        "            return precedents\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error retrieving precedents: {str(e)}\")\n",
        "            return SAMPLE_CASES[:k]  # Fallback to sample data\n",
        "\n",
        "    def analyze_case(self, case_data):\n",
        "        \"\"\"Analyze a legal case and generate an initial judgment\"\"\"\n",
        "        logger.info(f\"Starting case analysis for category: {case_data.get('case_category', 'Unspecified')}\")\n",
        "\n",
        "        # Extract case data\n",
        "        case_facts = case_data.get(\"case_facts\", \"\")\n",
        "        petitioner_arguments = case_data.get(\"petitioner_arguments\", \"\")\n",
        "        respondent_arguments = case_data.get(\"respondent_arguments\", \"\")\n",
        "        relevant_statutes = case_data.get(\"relevant_statutes\", [])\n",
        "\n",
        "        # Combined text for precedent search\n",
        "        combined_text = f\"{case_facts} {petitioner_arguments} {respondent_arguments}\"\n",
        "\n",
        "        # Retrieve relevant precedents\n",
        "        precedents = self.retrieve_relevant_precedents(combined_text)\n",
        "        precedent_text = \"\\n\\n\".join([\n",
        "            f\"PRECEDENT: {p['title']}\\nCOURT: {p['court']}\\nCITATION: {p['citation']}\\nSUMMARY: {p['content']}\"\n",
        "            for p in precedents\n",
        "        ])\n",
        "\n",
        "        # Format statutes\n",
        "        # For demo purposes, convert statute codes to full text if available\n",
        "        statute_texts = []\n",
        "        for statute in relevant_statutes:\n",
        "            if statute in SAMPLE_STATUTES:\n",
        "                statute_texts.append(f\"{statute}: {SAMPLE_STATUTES[statute]}\")\n",
        "            else:\n",
        "                statute_texts.append(statute)\n",
        "\n",
        "        statutes_text = \"\\n\".join(statute_texts)\n",
        "\n",
        "        # Generate legal analysis\n",
        "        try:\n",
        "            if callable(self.llm) and not hasattr(self.llm, 'run'):\n",
        "                # Simple mock LLM\n",
        "                legal_analysis = self.llm(combined_text)\n",
        "            else:\n",
        "                # LangChain LLM\n",
        "                legal_analysis_chain = LLMChain(llm=self.llm, prompt=self.case_analysis_prompt)\n",
        "                legal_analysis = legal_analysis_chain.run(\n",
        "                    case_facts=case_facts,\n",
        "                    petitioner_arguments=petitioner_arguments,\n",
        "                    respondent_arguments=respondent_arguments,\n",
        "                    statutes=statutes_text,\n",
        "                    precedents=precedent_text\n",
        "                )\n",
        "\n",
        "            # Process the analysis to extract structured information\n",
        "            # In a real system, this would be more sophisticated\n",
        "            sections = legal_analysis.split(\"\\n\\n\")\n",
        "\n",
        "            # Extract sections (simplified)\n",
        "            legal_issues = \"No legal issues identified.\"\n",
        "            fact_analysis = \"No fact analysis provided.\"\n",
        "            statute_application = \"No statute application provided.\"\n",
        "            precedent_consideration = \"No precedent consideration provided.\"\n",
        "            legal_reasoning = \"No detailed reasoning provided.\"\n",
        "            preliminary_judgment = \"No judgment provided.\"\n",
        "\n",
        "            # Attempt to extract sections if they exist\n",
        "            for section in sections:\n",
        "                if \"LEGAL ISSUES\" in section or \"IDENTIFICATION OF LEGAL ISSUES\" in section:\n",
        "                    legal_issues = section\n",
        "                elif \"ANALYSIS OF FACTS\" in section:\n",
        "                    fact_analysis = section\n",
        "                elif \"APPLICATION OF STATUTES\" in section:\n",
        "                    statute_application = section\n",
        "                elif \"PRECEDENT CONSIDERATION\" in section:\n",
        "                    precedent_consideration = section\n",
        "                elif \"LEGAL REASONING\" in section:\n",
        "                    legal_reasoning = section\n",
        "                elif \"PRELIMINARY JUDGMENT\" in section:\n",
        "                    preliminary_judgment = section\n",
        "\n",
        "            # Extract a clear decision if possible\n",
        "            decision = \"Undetermined\"\n",
        "            if \"in favor of petitioner\" in preliminary_judgment.lower():\n",
        "                decision = \"In favor of Petitioner\"\n",
        "            elif \"in favor of respondent\" in preliminary_judgment.lower():\n",
        "                decision = \"In favor of Respondent\"\n",
        "\n",
        "            # Generate a simple confidence score\n",
        "            confidence_score = 0.7  # Default mid-range confidence\n",
        "\n",
        "            # Parse precedent citations\n",
        "            precedent_citations = [\n",
        "                {\"citation\": p[\"citation\"], \"relevance\": \"High\" if i < 2 else \"Medium\"}\n",
        "                for i, p in enumerate(precedents)\n",
        "            ]\n",
        "\n",
        "            return {\n",
        "                \"full_analysis\": legal_analysis,\n",
        "                \"legal_issues\": legal_issues,\n",
        "                \"fact_analysis\": fact_analysis,\n",
        "                \"statute_application\": statute_application,\n",
        "                \"precedent_consideration\": precedent_consideration,\n",
        "                \"legal_reasoning\": legal_reasoning,\n",
        "                \"preliminary_judgment\": preliminary_judgment,\n",
        "                \"clear_decision\": decision,\n",
        "                \"precedent_citations\": precedent_citations,\n",
        "                \"confidence_score\": confidence_score,\n",
        "                \"case_data\": case_data\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during case analysis: {str(e)}\")\n",
        "            # Return a simplified response for demo purposes\n",
        "            return {\n",
        "                \"full_analysis\": \"Error during analysis\",\n",
        "                \"legal_issues\": \"Error during analysis\",\n",
        "                \"preliminary_judgment\": \"Unable to determine\",\n",
        "                \"clear_decision\": \"Error\",\n",
        "                \"precedent_citations\": [],\n",
        "                \"confidence_score\": 0.0,\n",
        "                \"error\": str(e),\n",
        "                \"case_data\": case_data\n",
        "            }"
      ],
      "metadata": {
        "id": "ZDMmyXOnfypQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AI Jury\n",
        "\n",
        "class AIJuryMember:\n",
        "    def __init__(self, perspective, llm):\n",
        "        \"\"\"Initialize an AI Jury member with a specific legal perspective\"\"\"\n",
        "        self.perspective = perspective\n",
        "        self.llm = llm\n",
        "        self.perspective_descriptions = {\n",
        "            \"strict_interpretation\": \"You focus on the literal meaning of statutes and strict precedent adherence.\",\n",
        "            \"progressive\": \"You consider evolving social contexts and the spirit of the law over literal interpretation.\",\n",
        "            \"rights_based\": \"You prioritize fundamental rights and constitutional principles in your analysis.\",\n",
        "            \"procedural\": \"You emphasize procedural correctness and due process in your analysis.\",\n",
        "            \"economic\": \"You consider economic efficiency and practical implications in your legal reasoning.\"\n",
        "        }\n",
        "        self._setup_prompt_template()\n",
        "\n",
        "    def _setup_prompt_template(self):\n",
        "        \"\"\"Set up the prompt template for this jury member\"\"\"\n",
        "        perspective_desc = self.perspective_descriptions.get(\n",
        "            self.perspective,\n",
        "            \"You analyze legal cases from a balanced perspective.\"\n",
        "        )\n",
        "\n",
        "        template = f\"\"\"\n",
        "        You are an AI legal expert with a {self.perspective} perspective on the law.\n",
        "        {perspective_desc}\n",
        "\n",
        "        Review the following case and provide your analysis and opinion:\n",
        "\n",
        "        CASE FACTS:\n",
        "        {{case_facts}}\n",
        "\n",
        "        PETITIONER'S ARGUMENTS:\n",
        "        {{petitioner_arguments}}\n",
        "\n",
        "        RESPONDENT'S ARGUMENTS:\n",
        "        {{respondent_arguments}}\n",
        "\n",
        "        INITIAL ANALYSIS BY AI JUDGE:\n",
        "        {{initial_analysis}}\n",
        "\n",
        "        Based on your {self.perspective} perspective, provide:\n",
        "        1. Your agreement or disagreement with the initial analysis\n",
        "        2. Your reasoning based on legal principles\n",
        "        3. Your recommended verdict (for Petitioner or for Respondent)\n",
        "        4. Confidence in your recommendation (Low, Medium, High)\n",
        "        \"\"\"\n",
        "\n",
        "        self.prompt_template = PromptTemplate(\n",
        "            input_variables=[\"case_facts\", \"petitioner_arguments\",\n",
        "                           \"respondent_arguments\", \"initial_analysis\"],\n",
        "            template=template\n",
        "        )\n",
        "\n",
        "    def analyze(self, judge_analysis):\n",
        "        \"\"\"Analyze the case from this jury member's perspective\"\"\"\n",
        "        try:\n",
        "            # Extract relevant data\n",
        "            case_data = judge_analysis[\"case_data\"]\n",
        "            case_facts = case_data.get(\"case_facts\", \"\")\n",
        "            petitioner_arguments = case_data.get(\"petitioner_arguments\", \"\")\n",
        "            respondent_arguments = case_data.get(\"respondent_arguments\", \"\")\n",
        "\n",
        "            # Get a summary of the initial analysis\n",
        "            initial_analysis_summary = judge_analysis[\"legal_issues\"] + \"\\n\" + judge_analysis[\"preliminary_judgment\"]\n",
        "\n",
        "            # Generate jury member's analysis\n",
        "            if callable(self.llm) and not hasattr(self.llm, 'run'):\n",
        "                # Simple mock for demo\n",
        "                response = f\"Based on my {self.perspective} perspective, I {'agree' if np.random.random() > 0.3 else 'disagree'} with the initial analysis. \" + \\\n",
        "                          f\"I recommend a verdict for {'Petitioner' if np.random.random() > 0.5 else 'Respondent'} with {['Low', 'Medium', 'High'][np.random.randint(0, 3)]} confidence.\"\n",
        "            else:\n",
        "                chain = LLMChain(llm=self.llm, prompt=self.prompt_template)\n",
        "                response = chain.run(\n",
        "                    case_facts=case_facts[:500],  # Truncate for length\n",
        "                    petitioner_arguments=petitioner_arguments[:300],\n",
        "                    respondent_arguments=respondent_arguments[:300],\n",
        "                    initial_analysis=initial_analysis_summary[:500]\n",
        "                )\n",
        "\n",
        "            # Parse the response to extract key elements (simplified)\n",
        "            agreement = \"Agreement\" if \"agree\" in response.lower() else \"Disagreement\"\n",
        "            verdict = \"For Petitioner\" if \"petitioner\" in response.lower() else \"For Respondent\"\n",
        "\n",
        "            # Extract confidence\n",
        "            confidence = \"Medium\"  # Default\n",
        "            if \"high confidence\" in response.lower():\n",
        "                confidence = \"High\"\n",
        "            elif \"low confidence\" in response.lower():\n",
        "                confidence = \"Low\"\n",
        "\n",
        "            return {\n",
        "                \"perspective\": self.perspective,\n",
        "                \"full_analysis\": response,\n",
        "                \"agreement\": agreement,\n",
        "                \"recommended_verdict\": verdict,\n",
        "                \"confidence\": confidence\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in jury member analysis ({self.perspective}): {str(e)}\")\n",
        "            return {\n",
        "                \"perspective\": self.perspective,\n",
        "                \"full_analysis\": f\"Error during analysis: {str(e)}\",\n",
        "                \"agreement\": \"Error\",\n",
        "                \"recommended_verdict\": \"Unable to determine\",\n",
        "                \"confidence\": \"Low\"\n",
        "            }\n",
        "\n",
        "class AIJurySystem:\n",
        "    def __init__(self, llm):\n",
        "        \"\"\"Initialize the AI Jury system with multiple jury members\"\"\"\n",
        "        self.llm = llm\n",
        "        self.jury_members = {\n",
        "            \"strict_interpretation\": AIJuryMember(\"strict_interpretation\", llm),\n",
        "            \"progressive\": AIJuryMember(\"progressive\", llm),\n",
        "            \"rights_based\": AIJuryMember(\"rights_based\", llm),\n",
        "            \"procedural\": AIJuryMember(\"procedural\", llm),\n",
        "            \"economic\": AIJuryMember(\"economic\", llm)\n",
        "        }\n",
        "\n",
        "    def deliberate(self, judge_analysis):\n",
        "        \"\"\"Conduct jury deliberation on a case\"\"\"\n",
        "        logger.info(\"Starting AI Jury deliberation process\")\n",
        "\n",
        "        # analysing the case\n",
        "        jury_analyses = {}\n",
        "        for name, member in self.jury_members.items():\n",
        "            logger.info(f\"Getting analysis from {name} jury member...\")\n",
        "            jury_analyses[name] = member.analyze(judge_analysis)\n",
        "\n",
        "        # Calculate voting results\n",
        "        verdict_counts = {\"For Petitioner\": 0, \"For Respondent\": 0, \"Undetermined\": 0}\n",
        "        for analysis in jury_analyses.values():\n",
        "            verdict = analysis.get(\"recommended_verdict\", \"Undetermined\")\n",
        "            verdict_counts[verdict] = verdict_counts.get(verdict, 0) + 1\n",
        "\n",
        "        # Determine majority\n",
        "        majority_verdict = max(verdict_counts.items(), key=lambda x: x[1])[0]\n",
        "        majority_percentage = verdict_counts[majority_verdict] / len(jury_analyses) * 100\n",
        "\n",
        "        # Generate overall confidence based on member confidence levels\n",
        "        confidence_map = {\"Low\": 0.3, \"Medium\": 0.6, \"High\": 0.9}\n",
        "        avg_confidence = sum(confidence_map.get(a.get(\"confidence\", \"Low\"), 0.3) for a in jury_analyses.values()) / len(jury_analyses)\n",
        "\n",
        "        # simplified debate\n",
        "        for_petitioner = [m for m, a in jury_analyses.items() if a.get(\"recommended_verdict\") == \"For Petitioner\"]\n",
        "        for_respondent = [m for m, a in jury_analyses.items() if a.get(\"recommended_verdict\") == \"For Respondent\"]\n",
        "\n",
        "        debate_summary = f\"AI Jury deliberation complete. {len(for_petitioner)} members ({', '.join(for_petitioner)}) \" + \\\n",
        "                        f\"voted for the Petitioner. {len(for_respondent)} members ({', '.join(for_respondent)}) \" + \\\n",
        "                        f\"voted for the Respondent. Majority verdict: {majority_verdict} ({majority_percentage:.1f}%).\"\n",
        "\n",
        "        return {\n",
        "            \"individual_analyses\": jury_analyses,\n",
        "            \"verdict_counts\": verdict_counts,\n",
        "            \"majority_verdict\": majority_verdict,\n",
        "            \"majority_percentage\": majority_percentage,\n",
        "            \"average_confidence\": avg_confidence,\n",
        "            \"debate_summary\": debate_summary\n",
        "        }"
      ],
      "metadata": {
        "id": "2lj04xeil3Qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AJDMS Main\n",
        "\n",
        "class AJDMS:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize the AI Judge Decision-Making System\"\"\"\n",
        "        logger.info(\"Initializing AJDMS...\")\n",
        "\n",
        "        self.llm = load_language_model()\n",
        "        self.vector_db = setup_vector_database()\n",
        "\n",
        "        # Initialize components\n",
        "        self.ai_judge = AIJudge(self.llm, self.vector_db)\n",
        "        self.ai_jury = AIJurySystem(self.llm)\n",
        "\n",
        "        # Case storage\n",
        "        self.cases = {}\n",
        "\n",
        "        logger.info(\"AJDMS initialized successfully\")\n",
        "\n",
        "    def process_case(self, case_data):\n",
        "        \"\"\"Process a new legal case through the system\"\"\"\n",
        "        logger.info(\"Processing new case...\")\n",
        "\n",
        "        # Generate case ID\n",
        "        case_id = f\"case_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
        "\n",
        "        # Step 1: AI Judge Analysis\n",
        "        judge_analysis = self.ai_judge.analyze_case(case_data)\n",
        "\n",
        "        # Step 2: AI Jury\n",
        "        jury_deliberation = self.ai_jury.deliberate(judge_analysis)\n",
        "\n",
        "        # Step 3: Final Verdict\n",
        "        final_verdict = self._generate_final_verdict(judge_analysis, jury_deliberation)\n",
        "\n",
        "        # Store case results\n",
        "        self.cases[case_id] = {\n",
        "            \"case_data\": case_data,\n",
        "            \"judge_analysis\": judge_analysis,\n",
        "            \"jury_deliberation\": jury_deliberation,\n",
        "            \"final_verdict\": final_verdict,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # Save to file\n",
        "        try:\n",
        "            with open(f\"case_data/{case_id}.json\", \"w\") as f:\n",
        "                json.dump(self.cases[case_id], f, indent=2)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error saving case data: {str(e)}\")\n",
        "\n",
        "        return {\n",
        "            \"case_id\": case_id,\n",
        "            \"final_verdict\": final_verdict,\n",
        "            \"judge_analysis\": judge_analysis,\n",
        "            \"jury_deliberation\": jury_deliberation\n",
        "        }\n",
        "\n",
        "    def _generate_final_verdict(self, judge_analysis, jury_deliberation):\n",
        "        \"\"\"Generate the final verdict considering both Judge and Jury inputs\"\"\"\n",
        "        judge_decision = judge_analysis.get(\"clear_decision\", \"Undetermined\")\n",
        "        jury_verdict = jury_deliberation.get(\"majority_verdict\", \"Undetermined\")\n",
        "\n",
        "        # for final decision\n",
        "        if judge_decision == jury_verdict:\n",
        "            final_decision = judge_decision\n",
        "            decision_confidence = max(judge_analysis.get(\"confidence_score\", 0.5),\n",
        "                                    jury_deliberation.get(\"average_confidence\", 0.5))\n",
        "            reasoning = f\"Both the AI Judge and AI Jury majority agree on this verdict.\"\n",
        "        else:\n",
        "            # In case of disagreement\n",
        "            jury_confidence = jury_deliberation.get(\"average_confidence\", 0.5)\n",
        "            judge_confidence = judge_analysis.get(\"confidence_score\", 0.5)\n",
        "\n",
        "            if jury_confidence > judge_confidence:\n",
        "                final_decision = jury_verdict\n",
        "                decision_confidence = jury_confidence\n",
        "                reasoning = f\"The AI Jury's consensus carries more weight in this case.\"\n",
        "            else:\n",
        "                final_decision = judge_decision\n",
        "                decision_confidence = judge_confidence\n",
        "                reasoning = f\"The AI Judge's analysis carries more weight in this case.\"\n",
        "\n",
        "        #citations from judge's analysis\n",
        "        citations = judge_analysis.get(\"precedent_citations\", [])\n",
        "\n",
        "        return {\n",
        "            \"decision\": final_decision,\n",
        "            \"confidence\": decision_confidence,\n",
        "            \"reasoning\": reasoning,\n",
        "            \"citations\": citations,\n",
        "            \"date\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    def get_case(self, case_id):\n",
        "        \"\"\"Retrieve a case by ID\"\"\"\n",
        "        if case_id in self.cases:\n",
        "            return self.cases[case_id]\n",
        "\n",
        "        # Try to load from file\n",
        "        try:\n",
        "            with open(f\"case_data/{case_id}.json\", \"r\") as f:\n",
        "                case_data = json.load(f)\n",
        "                self.cases[case_id] = case_data\n",
        "                return case_data\n",
        "        except:\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "gZfq9zJ-mEw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "\n",
        "def create_gradio_interface():\n",
        "    # Initialize the system\n",
        "    system = AJDMS()\n",
        "\n",
        "    # case submission function\n",
        "    def submit_case(case_facts, petitioner_arguments, respondent_arguments, statutes, case_category):\n",
        "        # case data\n",
        "        case_data = {\n",
        "            \"case_facts\": case_facts,\n",
        "            \"petitioner_arguments\": petitioner_arguments,\n",
        "            \"respondent_arguments\": respondent_arguments,\n",
        "            \"relevant_statutes\": [s.strip() for s in statutes.split(\"\\n\") if s.strip()],\n",
        "            \"case_category\": case_category\n",
        "        }\n",
        "\n",
        "        # Process the case\n",
        "        result = system.process_case(case_data)\n",
        "\n",
        "        # Extract results\n",
        "        judge_analysis = result[\"judge_analysis\"]\n",
        "        jury_deliberation = result[\"jury_deliberation\"]\n",
        "        final_verdict = result[\"final_verdict\"]\n",
        "\n",
        "        judge_output = f\"## AI Judge Analysis\\n\\n\" + \\\n",
        "                      f\"### Legal Issues\\n{judge_analysis.get('legal_issues', 'Not provided')}\\n\\n\" + \\\n",
        "                      f\"### Preliminary Judgment\\n{judge_analysis.get('preliminary_judgment', 'Not provided')}\\n\\n\"\n",
        "\n",
        "        jury_output = f\"## AI Jury Deliberation\\n\\n\" + \\\n",
        "                     f\"### Debate Summary\\n{jury_deliberation.get('debate_summary', 'Not provided')}\\n\\n\" + \\\n",
        "                     f\"### Voting Results\\n\" + \\\n",
        "                     f\"For Petitioner: {jury_deliberation.get('verdict_counts', {}).get('For Petitioner', 0)}\\n\" + \\\n",
        "                     f\"For Respondent: {jury_deliberation.get('verdict_counts', {}).get('For Respondent', 0)}\\n\\n\"\n",
        "\n",
        "        verdict_output = f\"## Final Verdict\\n\\n\" + \\\n",
        "                        f\"### Decision\\n{final_verdict.get('decision', 'Undetermined')}\\n\\n\" + \\\n",
        "                        f\"### Reasoning\\n{final_verdict.get('reasoning', 'Not provided')}\\n\\n\" + \\\n",
        "                        f\"### Confidence\\n{final_verdict.get('confidence', 0.0):.2f}\\n\\n\" + \\\n",
        "                        f\"### Citations\\n\" + \\\n",
        "                        \"\\n\".join([f\"- {c.get('citation', 'Unknown')} (Relevance: {c.get('relevance', 'Unknown')})\"\n",
        "                                 for c in final_verdict.get('citations', [])])\n",
        "\n",
        "        case_id = result[\"case_id\"]\n",
        "\n",
        "        return judge_output, jury_output, verdict_output, case_id\n",
        "\n",
        "    # Create the interface\n",
        "    with gr.Blocks(title=\"AI Judge Decision-Making System\") as interface:\n",
        "        gr.Markdown(\"# AI Judge Decision-Making System (AJDMS)\")\n",
        "        gr.Markdown(\"Submit a legal case for AI analysis\")\n",
        "\n",
        "        with gr.Tab(\"Case Submission\"):\n",
        "            case_category = gr.Dropdown(\n",
        "                choices=[\"Constitutional\", \"Criminal\", \"Civil\", \"Administrative\", \"Environmental\", \"Intellectual Property\"],\n",
        "                label=\"Case Category\"\n",
        "            )\n",
        "            case_facts"
      ],
      "metadata": {
        "id": "W2KUIk9_mJ9O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}